{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CAT_FCOLS = ['card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'dist2']\n",
    "C_FCOLS = [f'C{i}' for i in range(1, 15)]\n",
    "D_FCOLS = [f'D{i}' for i in range(1, 16)]\n",
    "V_FCOLS = [f'V{i}' for i in range(1, 340)] \n",
    "FLOAT64_TCOLS = CAT_FCOLS + C_FCOLS + D_FCOLS + V_FCOLS\n",
    "FLOAT64_ICOLS = [f'id_0{i}' for i in range(1, 10)] + ['id_10', 'id_11', 'id_13', 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26', 'id_32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 590540\n",
      "Number of Test Examples = 506691\n",
      "\n",
      "Number of Training Examples with Identity = 144233\n",
      "Number of Test Examples with Identity = 141907\n",
      "\n",
      "Training X Shape = (590540, 434)\n",
      "Training y Shape = (590540,)\n",
      "Test X Shape = (506691, 433)\n",
      "\n",
      "Training Set Memory Usage = 1063.29 MB\n",
      "Test Set Memory Usage = 908.45 MB\n",
      "\n",
      "CPU times: user 43.8 s, sys: 12.6 s, total: 56.4 s\n",
      "Wall time: 55.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv', dtype=dict.fromkeys(FLOAT64_ICOLS, np.float32))\n",
    "df_test_identity = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv', dtype=dict.fromkeys(FLOAT64_ICOLS, np.float32))\n",
    "df_train_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv', dtype=dict.fromkeys(FLOAT64_TCOLS, np.float32))\n",
    "df_test_transaction = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv', dtype=dict.fromkeys(FLOAT64_TCOLS, np.float32))\n",
    "X_train = pd.merge(df_train_transaction, df_train_identity, how='left', on='TransactionID')\n",
    "X_test = pd.merge(df_test_transaction, df_test_identity, how='left', on='TransactionID')\n",
    "\n",
    "print('Number of Training Examples = {}'.format(df_train_transaction.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test_transaction.shape[0]))\n",
    "print('Number of Training Examples with Identity = {}'.format(df_train_identity.shape[0]))\n",
    "print('Number of Test Examples with Identity = {}\\n'.format(df_test_identity.shape[0]))\n",
    "print('Training X Shape = {}'.format(X_train.shape))\n",
    "print('Training y Shape = {}'.format(X_train['isFraud'].shape))\n",
    "print('Test X Shape = {}\\n'.format(X_test.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(X_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Memory Usage = {:.2f} MB\\n'.format(X_test.memory_usage().sum() / 1024**2))\n",
    "\n",
    "del df_train_identity, df_test_identity, df_train_transaction, df_test_transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grazder's [Filling card NaNs](https://www.kaggle.com/grazder/filling-card-nans) kernel inspired me to create this helper function. It basically checks the value counts of two given variables and outputs how many different values can dependent_var get for every independent variable value. This is one way to understand causality between two vectors which can't be seen by pearson correlation.\n",
    "\n",
    "This function can be used to reveal connection between features and for imputation. There isn't any standard threshold for deciding dependent/not dependent, so if you have a hunch just use that information. There are some examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dependency(independent_var, dependent_var):\n",
    "    \n",
    "    independent_uniques = []\n",
    "    temp_df = pd.concat([X_train[[independent_var, dependent_var]], X_test[[independent_var, dependent_var]]])\n",
    "    \n",
    "    for value in temp_df[independent_var].unique():\n",
    "        independent_uniques.append(temp_df[temp_df[independent_var] == value][dependent_var].value_counts().shape[0])\n",
    "\n",
    "    values = pd.Series(data=independent_uniques, index=temp_df[independent_var].unique())\n",
    "    \n",
    "    N = len(values)\n",
    "    N_dependent = len(values[values == 1])\n",
    "    N_notdependent = len(values[values > 1])\n",
    "    N_null = len(values[values == 0])\n",
    "        \n",
    "    print(f'In {independent_var}, there are {N} unique values')\n",
    "    print(f'{N_dependent}/{N} have one unique {dependent_var} value')\n",
    "    print(f'{N_notdependent}/{N} have more than one unique {dependent_var} values')\n",
    "    print(f'{N_null}/{N} have only missing {dependent_var} values\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "16274/17091 have one unique card2 value\n",
      "296/17091 have more than one unique card2 values\n",
      "521/17091 have only missing card2 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'card2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "17028/17091 have one unique card3 value\n",
      "29/17091 have more than one unique card3 values\n",
      "34/17091 have only missing card3 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'card3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "17037/17091 have one unique card4 value\n",
      "0/17091 have more than one unique card4 values\n",
      "54/17091 have only missing card4 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'card4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "16521/17091 have one unique card5 value\n",
      "307/17091 have more than one unique card5 values\n",
      "263/17091 have only missing card5 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'card5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "16898/17091 have one unique card6 value\n",
      "158/17091 have more than one unique card6 values\n",
      "35/17091 have only missing card6 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'card6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "14560/17091 have one unique addr2 value\n",
      "366/17091 have more than one unique addr2 values\n",
      "2165/17091 have only missing addr2 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'addr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "6754/17091 have one unique P_emaildomain value\n",
      "9887/17091 have more than one unique P_emaildomain values\n",
      "450/17091 have only missing P_emaildomain values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'P_emaildomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In card1, there are 17091 unique values\n",
      "5439/17091 have one unique R_emaildomain value\n",
      "5569/17091 have more than one unique R_emaildomain values\n",
      "6083/17091 have only missing R_emaildomain values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('card1', 'R_emaildomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In P_emaildomain, there are 61 unique values\n",
      "7/61 have one unique R_emaildomain value\n",
      "53/61 have more than one unique R_emaildomain values\n",
      "1/61 have only missing R_emaildomain values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('P_emaildomain', 'R_emaildomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addr1, there are 442 unique values\n",
      "243/442 have one unique P_emaildomain value\n",
      "189/442 have more than one unique P_emaildomain values\n",
      "10/442 have only missing P_emaildomain values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('addr1', 'P_emaildomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In dist1, there are 2739 unique values\n",
      "2738/2739 have one unique C3 value\n",
      "0/2739 have more than one unique C3 values\n",
      "1/2739 have only missing C3 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('dist1', 'C3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use this function?\n",
    "* Found connection between **R_emaildomain** and **C5**\n",
    "* Checking what are the values can C5 take\n",
    "* Filling the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In R_emaildomain, there are 61 unique values\n",
      "60/61 have one unique C5 value\n",
      "0/61 have more than one unique C5 values\n",
      "1/61 have only missing C5 values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_dependency('R_emaildomain', 'C5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    135867\n",
       "Name: C5, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[~X_test['R_emaildomain'].isnull()]['C5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test['C5'].fillna(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
